{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f820db96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\20190735\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\20190735\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\20190735\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Install Pillow, pytesseract and translate, via Conda or pip\n",
    "# Install Tesseract on your PC, https://github.com/UB-Mannheim/tesseract/wiki\n",
    "from pytesseract import pytesseract\n",
    "from translate import Translator\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6217da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribes image to text\n",
    "def transcribe(img):\n",
    "    transcription = pytesseract.image_to_string(img)\n",
    "\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26a2c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = [i.split('\\n') for i in text.split(' ')]\n",
    "    text = [item for sublist in text for item in sublist]\n",
    "    text = [i for i in text if i not in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "    text = text.lower() \n",
    "    text = text.strip()  \n",
    "    text = re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    \n",
    "    # Lemmatize\n",
    "    text = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "    text = ' '.join([i for i in text if len(i) > 1])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21bf176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_folder(img_folder):\n",
    "    names = []\n",
    "    texts = []\n",
    "    unprocessed_texts = []\n",
    "    for img_name in os.listdir(img_folder):\n",
    "        img_path = os.path.join(img_folder, img_name)\n",
    "        \n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            names.append(img_path)\n",
    "            text = transcribe(img)\n",
    "            unprocessed_texts.append(text)\n",
    "            text = preprocess(text)\n",
    "            texts.append(text)\n",
    "        except TypeError:\n",
    "            \"error\"\n",
    "            \n",
    "    return names, texts, unprocessed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479c8025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(texts):\n",
    "    filename = 'pipeline.sav'\n",
    "    pipeline = pickle.load(open(filename, 'rb'))\n",
    "    target = pipeline.predict(texts)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0713ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "def create_data(img_folder, csv_file):\n",
    "    names, texts, unprocessed_texts = transcribe_folder(img_folder)\n",
    "    timestamps = [os.path.basename(i).split('.')[0] for i in names]\n",
    "    target = classify(texts)\n",
    "    df = pd.DataFrame()\n",
    "    df['Timestamp'] = timestamps\n",
    "    df['Text'] = unprocessed_texts\n",
    "    df['Target'] = target\n",
    "    df.to_csv(csv_file, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2612c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_instance(instance):\n",
    "    path_img = os.path.join(r'data\\keylogging', instance)\n",
    "    path_img = os.path.join(path_img, 'images')\n",
    "    path_c = os.path.join(r'data\\keylogging', instance)\n",
    "    path_c = os.path.join(path_c, 'classification.csv')\n",
    "    \n",
    "    create_data(path_img, path_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17fb820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_instance('instance_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
